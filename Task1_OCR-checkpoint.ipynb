{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  <div style=\"text-align: center\">The Sparks Foundations IoT & Computer Vision intern </div>\n",
    "<br>\n",
    "<font size=4>Task 1: Character detector  </font>  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=4>\n",
    "By: Md. Yeasin Sheikh</font> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.4>In this section we will look an overview of how we can use openCv and Tesseract to extract data/Text from image. It can be applied to hand-Writing images and video.\n",
    "\n",
    "‚ö† Make sure you have Tesseract on your system. else follow github readme.md . </font>\n",
    "\n",
    "<font  size=4.5> Let's see how its woks </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages we need\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import cv2\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>locate the path of tesseract.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'I:\\ML_Install\\tesseract\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Characters\n",
    "I'm going to use images from assets directory  \n",
    "openCV use BGR image but pytesseract need RGB image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/slide1.png') # getting image from directory\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # conveting into RGB image\n",
    "\n",
    "#variables for simplicty\n",
    "rectColor = (28,255,1) \n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL \n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "boxes = pytesseract.image_to_boxes(img_rgb) # it helps to get the character's positions\n",
    "\n",
    "for b in boxes.splitlines():\n",
    "    # print(b)\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h=  int(b[1]),int(b[2]),int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x, imgHeight-y), (w, imgHeight- h), rectColor, 1) # draw the rectangle\n",
    "    cv2.putText(img, b[0],(x,imgHeight-y+20),font,1, fontColor ) # put char on image \n",
    "\n",
    "cv2.imshow(\"Detect Every Character\", img)\n",
    "cv2.waitKey(0) # wait until we press 'q' or close the popUp window\n",
    "cv2.destroyAllWindows() # clear previous windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Words\n",
    "to get word we need to use <font color='blue'>ytesseract.image_to_data()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/ocr2.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, config='--psm 6') # return texts from image\n",
    "print(\"Text from Image:\\n\"+text)\n",
    "boxes = pytesseract.image_to_data(img_rgb) \n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            cv2.putText(img, b[11],(x,y), font, .01, fontColor, 1)\n",
    "    \n",
    "cv2.imshow(\"Image from PDF-'The Secret'\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Digits\n",
    "This <font size=3.5 color='green'> 'outputbase digits'</font> parameter return only digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/digit.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "conf = r'--oem 3 --psm 6 outputbase digits'\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL \n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "boxes = pytesseract.image_to_boxes(img_rgb, config= conf)\n",
    "\n",
    "for b in boxes.splitlines():\n",
    "    # print(b)\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h=  int(b[1]),int(b[2]),int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x, imgHeight-y), (w, imgHeight- h), rectColor, 1)\n",
    "    cv2.putText(img, b[0],(x,imgHeight-y+20),font,1, fontColor )\n",
    "cv2.imshow(\"Detect Every Digit\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bengali word detection\n",
    "\n",
    "<font size=3.5>By default pytesseract use English, we have to use <font color='blue'>lang</font> parameter for differents language. </font>  \n",
    "According to this opencv forum, putText is only able to support a small ascii subset of characters and does not support unicode characters which are other symboles like chinese and arabic characters. \n",
    "However, you can try to use PIL instead üòÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/bnQoute.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "conf = r'--oem 3 --psm 6'\n",
    "langs = 'ben'\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, lang=langs, config= conf)\n",
    "print(text)\n",
    "boxes = pytesseract.image_to_data(img_rgb, lang=langs, config=conf)\n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            \n",
    "cv2.imshow(\"Bengal \", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Language word detecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>By default pytesseract use English, we have to pass value through <font color='blue'>lang</font> parameter for differents language. Also there could be some collision while mixing multiple languages.</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/multilan.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "conf = r'--oem 3 --psm 6'\n",
    "langs = 'ben+urd+eng+hin'\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, lang=langs, config= conf)\n",
    "print(text)\n",
    "boxes = pytesseract.image_to_data(img_rgb, lang=langs, config=conf)\n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            \n",
    "            \n",
    "cv2.imshow(\"Multi-Language \", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for your time üôè\n",
    "<font size=4> I would greatly appreciate it if you kindly give me some feedback on this project. üòÅ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
